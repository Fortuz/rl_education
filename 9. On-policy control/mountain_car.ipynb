{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da821e0-a7d9-48b1-a92a-696c1b6bc491",
   "metadata": {},
   "source": [
    "![Logo](assets/logo.png)\n",
    "\n",
    "Made by **Domonkos Nagy**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Fortuz/rl_education/blob/main/9.%20On-policy%20Control/mountain_car.ipynb)\n",
    "\n",
    "# Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df8515e-60e6-48a9-b98a-6d13980f492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a188b4-c7ed-4990-b6f8-09f6e9bfa302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')  # Creating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b524b277-2b42-4154-afb7-b453d3fcefb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_ACTIONS: 3\n",
      "\n",
      "\tPos.  Vel.\n",
      "LOW:\t[-1.2  -0.07]\n",
      "HIGH:\t[0.6  0.07]\n"
     ]
    }
   ],
   "source": [
    "LOW = env.observation_space.low\n",
    "HIGH = env.observation_space.high\n",
    "N_ACTIONS = env.action_space.n\n",
    "\n",
    "print(f'N_ACTIONS: {N_ACTIONS}\\n')\n",
    "print('\\tPos.  Vel.')\n",
    "print(f'LOW:\\t{LOW}')\n",
    "print(f'HIGH:\\t{HIGH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af6170d0-6f90-40d4-a94f-e2776d170243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TiledQTable:\n",
    "    def __init__(self, offsets, n_actions, n_bins):\n",
    "        self.tilings = []\n",
    "        self.n_tilings = len(offsets)\n",
    "        self.n_actions = n_actions\n",
    "        n_dims = len(offsets[0])\n",
    "\n",
    "        # Create tilings\n",
    "        for offset in offsets:\n",
    "            tiling = [np.linspace(LOW[dim], HIGH[dim], n_bins + 1)[1:-1] + offset[dim] for dim in range(n_dims)]\n",
    "            self.tilings.append(tiling)\n",
    "\n",
    "        # Initialize q-table\n",
    "        shape = (self.n_tilings, ) + (n_bins, ) * n_dims + (n_actions, )\n",
    "        self.q_table = np.zeros(shape)\n",
    "\n",
    "    def __getitem__(self, coords):\n",
    "        # Coords is a state-action pair\n",
    "        print(len(self.q_table.shape) - len(coords))\n",
    "        if len(self.q_table.shape) - len(coords) == 0:\n",
    "            val = 0\n",
    "            state = coords[:-1]\n",
    "            action = coords[-1]\n",
    "\n",
    "            for i, tiling in enumerate(self.tilings):\n",
    "                ind = [i]\n",
    "                for dim in range(len(state)):\n",
    "                    ind.append(np.searchsorted(tiling[dim], state[dim]))\n",
    "                val += self.q_table[tuple(ind) + (action, )]\n",
    "\n",
    "            return val\n",
    "\n",
    "        # Coords is a state\n",
    "        elif len(self.q_table.shape) - len(coords) == 1: \n",
    "            vals = np.zeros(self.n_actions)\n",
    "            state = coords\n",
    "\n",
    "            for i, tiling in enumerate(self.tilings):\n",
    "                ind = [i]\n",
    "                for dim in range(len(state)):\n",
    "                    ind.append(np.searchsorted(tiling[dim], state[dim]))\n",
    "                vals += self.q_table[tuple(ind)]\n",
    "\n",
    "            return vals\n",
    "\n",
    "    def __setitem__(self, coords, new):\n",
    "        old = self.__getitem__(coords)\n",
    "        state = coords[:-1]\n",
    "        action = coords[-1]\n",
    "\n",
    "        for i, tiling in enumerate(self.tilings):\n",
    "            ind = [i]\n",
    "            for dim in range(len(coords)):\n",
    "                ind.append(np.searchsorted(tiling[dim], state[dim]))\n",
    "            self.q_table[tuple(ind) + (action, )] += (new - old) / self.n_tilings\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        shape = args[0].shape\n",
    "        z = np.zeros(shape)\n",
    "\n",
    "        for i in np.ndindex(shape):\n",
    "            x = [arg[i] for arg in args]\n",
    "            z[i] = self.__getitem__(x)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e1a45b7-7150-483e-8548-67e185e4b347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N_TILINGS = 8  # number of tilings\n",
    "N_BINS = 8  # number of bins per dimension per tiling\n",
    "N_EPISODES = 100_000  # number of learning steps\n",
    "ALPHA = 0.1  # learning rate\n",
    "GAMMA = 1  # discount rate\n",
    "EPSILON = 0.1  # exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6db294a-261e-4b7f-9e90-fd5a90383e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set asymmetrical offsets to avoid artifacts in\n",
    "# generalization; see Sutton & Barto pg. 218-220 for details\n",
    "tile_width = (HIGH - LOW) / N_BINS\n",
    "unit = tile_width / N_TILINGS\n",
    "offsets = [(unit[0] * i, 3 * unit[1] * i) for i in range(N_TILINGS)]\n",
    "\n",
    "# Initialize tiled q-table\n",
    "tqt = TiledQTable(offsets, N_ACTIONS, N_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4dd76fa-9c7a-457b-8647-1c73a2056333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epsilon-greedy action selection\n",
    "def select_action(epsilon, state):\n",
    "    if np.random.rand() > epsilon:\n",
    "        return np.argmax(tqt[state])\n",
    "    else:\n",
    "        return env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ce23eb1-bf19-4b60-b183-91e3d812d9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68236694aa704dc78ab4f64264f7ef96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     14\u001b[0m     new_action \u001b[38;5;241m=\u001b[39m select_action(EPSILON, state)\n\u001b[0;32m---> 15\u001b[0m     target \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \u001b[43mGAMMA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtqt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_action\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m tqt[(state, action)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ALPHA \u001b[38;5;241m*\u001b[39m (target \u001b[38;5;241m-\u001b[39m tqt[(state, action)])\n\u001b[1;32m     18\u001b[0m state \u001b[38;5;241m=\u001b[39m new_state\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "for episode in trange(N_EPISODES):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    action = select_action(EPSILON, state)\n",
    "\n",
    "    while not done:\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        target = reward\n",
    "\n",
    "        if not done:\n",
    "            new_action = select_action(EPSILON, state)\n",
    "            target = reward + GAMMA * tqt[(new_state, new_action)]\n",
    "        tqt[(state, action)] += ALPHA * (target - tqt[(state, action)])\n",
    "\n",
    "        state = new_state\n",
    "        action = new_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6c52c-7a5b-4739-b990-4bccd720a1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
