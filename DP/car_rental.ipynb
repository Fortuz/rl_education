{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jack’s Car Rental\n",
    "\n",
    "Jack manages two locations for a nationwide car\n",
    "rental company. Each day, some number of customers arrive at each location to rent cars.\n",
    "If Jack has a car available, he rents it out and is credited \\$10 by the national company.\n",
    "If he is out of cars at that location, then the business is lost. Cars become available for\n",
    "renting the day after they are returned. To help ensure that cars are available where\n",
    "they are needed, Jack can move them between the two locations overnight, at a cost of\n",
    "\\$2 per car moved. We assume that the number of cars requested and returned at each\n",
    "location are Poisson random variables, meaning that the probability that the number is\n",
    "n is $\\frac{\\lambda^n}{n!}e^{-\\lambda}$, where $n$ is the expected number. Suppose $\\lambda$ is 3 and 4 for rental requests at\n",
    "the first and second locations and 3 and 2 for returns. One of Jack’s employees at the first location\n",
    "rides a bus home each night and lives near the second location. She is happy to shuttle\n",
    "one car to the second location for free. Each additional car still costs \\$2, as do all cars\n",
    "moved in the other direction. In addition, Jack has limited parking space at each location.\n",
    "If more than 10 cars are kept overnight at a location (after any moving of cars), then an\n",
    "additional cost of \\$4 must be incurred to use a second parking lot (independent of how\n",
    "many cars are kept there). To simplify the problem slightly,\n",
    "we assume that there can be no more than 20 cars at each location (any additional cars\n",
    "are returned to the nationwide company, and thus disappear from the problem) and a\n",
    "maximum of five cars can be moved from one location to the other in one night. We take\n",
    "the discount rate to be $\\gamma = 0.9$ and formulate this as a continuing finite MDP, where\n",
    "the time steps are days, the state is the number of cars at each location at the end of\n",
    "the day, and the actions are the net numbers of cars moved between the two locations\n",
    "overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=0, suppress=True, linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "GAMMA = 0.9 # discount rate\n",
    "LAMBDA_RENTALS_A = 3\n",
    "LAMBDA_RENTALS_B = 4\n",
    "LAMBDA_RETURNS_A = 3\n",
    "LAMBDA_RETURNS_B = 2\n",
    "POISSON_LIMIT = 11 # for any n over this, the probability is truncated to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize value and policy tables\n",
    "v_estimations = np.zeros((21,21))\n",
    "policy = np.zeros((21,21), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson = {}\n",
    "\n",
    "# calculating poisson values for efficiency\n",
    "for l in [LAMBDA_RENTALS_A, LAMBDA_RENTALS_B, LAMBDA_RETURNS_A, LAMBDA_RETURNS_B]:\n",
    "    for n in range(POISSON_LIMIT):\n",
    "        poisson[(l, n)] = (np.power(l, n) / math.factorial(n)) * np.exp(-l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the expected value of an action in a given state\n",
    "def action_value(state, action):\n",
    "    N_CARS_A = state[0] - action\n",
    "    N_CARS_B = state[1] + action\n",
    "\n",
    "    # if the action is illegal in the state, we simply return -infinity\n",
    "    if (N_CARS_A < 0 or N_CARS_B < 0 or N_CARS_A > 20 or N_CARS_B > 20):\n",
    "        return -np.inf\n",
    "\n",
    "    sum_reward = 0\n",
    "    action_reward = abs(action) * -2\n",
    "\n",
    "    # one car can be taken from a to b for free\n",
    "    if action > 0:\n",
    "        action_reward += 2\n",
    "    \n",
    "    # keeping more than 10 cars at a location has a cost of $4\n",
    "    if N_CARS_A > 10:\n",
    "        action_reward -= 4\n",
    "    \n",
    "    if N_CARS_B > 10:\n",
    "        action_reward -= 4\n",
    "\n",
    "    for n_rentals_a in range(POISSON_LIMIT):\n",
    "        for n_rentals_b in range(POISSON_LIMIT):\n",
    "\n",
    "            # number of rentals should not be higher than the number of available cars\n",
    "            real_rentals_a = min(n_rentals_a, N_CARS_A)\n",
    "            real_rentals_b = min(n_rentals_b, N_CARS_B)\n",
    "\n",
    "            for n_returns_a in range(POISSON_LIMIT):\n",
    "                for n_returns_b in range(POISSON_LIMIT):\n",
    "\n",
    "                    # number of returns should not be higher than the max number of cars\n",
    "                    n_cars_a = min(N_CARS_A - real_rentals_a + n_returns_a, 20)\n",
    "                    n_cars_b = min(N_CARS_B - real_rentals_b + n_returns_b, 20)\n",
    "                    new_state = (n_cars_a, n_cars_b)\n",
    "                    \n",
    "                    # joint probability of the rentals and returns happening at both places\n",
    "                    prob_rentals = poisson[(LAMBDA_RENTALS_A, n_rentals_a)] * poisson[(LAMBDA_RENTALS_B, n_rentals_b)]\n",
    "                    prob_returns = poisson[(LAMBDA_RETURNS_A, n_returns_a)] * poisson[(LAMBDA_RETURNS_B, n_returns_b)]\n",
    "                    prob = prob_returns * prob_rentals\n",
    "\n",
    "                    # add the expected reward to the sum\n",
    "                    rental_reward = 10 * (real_rentals_a + real_rentals_b)\n",
    "                    reward = action_reward + rental_reward\n",
    "                    sum_reward += prob * (reward + GAMMA * v_estimations[new_state])\n",
    "\n",
    "    # this is the expected reward after taking the action and following the current policy after\n",
    "    return sum_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-place policy evaluation\n",
    "def policy_evaluation(theta=0.01):\n",
    "    delta = theta\n",
    "\n",
    "    while delta >= theta:\n",
    "        delta = 0\n",
    "        for n_cars_a in range(21):\n",
    "            for n_cars_b in range(21):\n",
    "                state = (n_cars_a, n_cars_b)\n",
    "\n",
    "                old_value = v_estimations[state]\n",
    "                action = policy[state]\n",
    "\n",
    "                v_estimations[state] = action_value(state, action)\n",
    "                delta = max(delta, abs(old_value - v_estimations[state]))\n",
    "        \n",
    "        print(f\"delta={delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement():\n",
    "    print(\"Improving policy...\")\n",
    "    policy_stable = True\n",
    "\n",
    "    for n_cars_a in range(21):\n",
    "        for n_cars_b in range(21):\n",
    "            state = (n_cars_a, n_cars_b)\n",
    "            old_action = policy[state]\n",
    "\n",
    "            action_values = {}\n",
    "\n",
    "            # calculate the value of taking each action\n",
    "            for action in range(-5,6):\n",
    "                action_values[action] = action_value(state, action)\n",
    " \n",
    "            # keep a list of best actions, so if more equi-best actions are present,\n",
    "            # and the new policy selects a different one than the old, policy_stable\n",
    "            # is still True\n",
    "            best_actions = []\n",
    "            best_value = -np.inf\n",
    "\n",
    "            for action, value in action_values.items():\n",
    "                if value > best_value:\n",
    "                    best_actions = [action]\n",
    "                    best_value = value\n",
    "                elif value == best_value:\n",
    "                    best_actions.append(action)\n",
    "            \n",
    "            policy[state] = best_actions[0]\n",
    "            policy_stable = policy_stable and old_action in best_actions\n",
    "\n",
    "    return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate until optimal policy is found\n",
    "policy_stable = False\n",
    "i = 1\n",
    "\n",
    "while not policy_stable:\n",
    "    display.clear_output()\n",
    "    print(f\"*** Iteration #{i} ***\")\n",
    "\n",
    "    policy_evaluation()\n",
    "    policy_stable = policy_improvement()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print value table\n",
    "print(v_estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print optimal policy\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "    \n",
    "sns.heatmap(np.flip(policy, axis=0), cmap='viridis',\n",
    "            linecolor='white', linewidths=0.05, square=True,\n",
    "            yticklabels=np.arange(21 - 1, -1, -1))\n",
    "\n",
    "plt.title(f'Values of the optimal policy')\n",
    "plt.ylabel('Cars at location 1')\n",
    "plt.xlabel('Cars at location 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
