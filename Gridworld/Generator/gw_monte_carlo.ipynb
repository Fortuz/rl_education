{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo](assets/logo.png)\n",
    "\n",
    "Made by **Zolt√°n Barta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://colab.research.google.com/assets/colab-badge.svg\">](https://colab.research.google.com/github/Fortuz/rl_education/blob/main/Gridworld/Generator/gw_monte_carlo.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Methods in Gridworld\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook explores the application of **Monte Carlo reinforcement learning** techniques in a **Gridworld** environment. Monte Carlo methods estimate value functions and optimize policies through experience-based sampling, making them a powerful tool in reinforcement learning. The implementation leverages Python libraries such as **NumPy, Gymnasium, and Matplotlib** to simulate and analyze agent behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Fortuz/rl_education/main/Gridworld/Generator/gridworld.py -O gridworld.py\n",
    "!wget https://raw.githubusercontent.com/Fortuz/rl_education/main/Gridworld/Generator/FreeMono.ttf -O FreeMono.ttf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from gridworld import Gridworld\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State types:\n",
      "[[0 0 0 1]\n",
      " [0 2 0 1]\n",
      " [0 0 0 0]]\n",
      "Rewards:\n",
      "[[ 0  0  0  1]\n",
      " [ 0  0  0 -1]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_types = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 2, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "],dtype=int)\n",
    "shape = state_types.shape\n",
    "\n",
    "\n",
    "\n",
    "rewards = np.zeros(shape, dtype=int) * -1\n",
    "rewards[0, 3] = 1\n",
    "rewards[1, 3] = -1\n",
    "\n",
    "assert state_types.shape == rewards.shape\n",
    "\n",
    "# Q-table\n",
    "q_table = np.zeros(shape + (4,))\n",
    "\n",
    "# Slip probabilities\n",
    "\n",
    "slip = {\n",
    "    'left': 0.0,\n",
    "    'right': 0.0,\n",
    "    'backward': 0\n",
    "}\n",
    "\n",
    "# Initializing gridworld\n",
    "gw = Gridworld(state_types, rewards, q_table, gamma=0.9, step_reward=0)\n",
    "\n",
    "print('State types:')\n",
    "print(state_types)\n",
    "print('Rewards:')\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `simulate` function runs a single episode in the **Gridworld** environment using a given **policy**. It follows the agent's movement, records the trajectory, accumulates rewards, and stops when a terminal state is reached or a maximum number of steps is taken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def simulate(gw, policy, max_steps=100):\n",
    "    \"\"\"\n",
    "    Simulates a single episode in the Gridworld environment following the given policy.\n",
    "\n",
    "    Parameters:\n",
    "    gw (Gridworld): The Gridworld object.\n",
    "    policy (np.ndarray): The policy array mapping states to actions.\n",
    "    max_steps (int): Maximum number of steps before termination.\n",
    "\n",
    "    Returns:\n",
    "    trajectory (list): List of (state, action, reward) tuples representing the agent's trajectory.\n",
    "    total_reward (float): The total reward collected in the episode.\n",
    "    steps (int): The number of steps taken in the episode.\n",
    "    \"\"\"\n",
    "    # Set starting position as the lower-left corner (bottom row, first column)\n",
    "    state = (gw.state_types.shape[0] - 1, 0)\n",
    "    \n",
    "    # Ensure the starting position is a valid (empty) state\n",
    "    if gw.state_types[state] != 0:\n",
    "        raise ValueError(\"Starting position (lower-left corner) is not a valid empty state.\")\n",
    "\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    trajectory = []\n",
    "\n",
    "    direction_to_offset = {\n",
    "        0: (-1, 0),  # Up\n",
    "        1: (0, 1),   # Right\n",
    "        2: (1, 0),   # Down\n",
    "        3: (0, -1),  # Left\n",
    "    }\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    " \n",
    "        action = policy(state)\n",
    "\n",
    "       \n",
    "        # Compute next state\n",
    "        i_off, j_off = direction_to_offset[action]\n",
    "        next_state = (max(0, min(state[0] + i_off, gw.state_types.shape[0] - 1)),\n",
    "                      max(0, min(state[1] + j_off, gw.state_types.shape[1] - 1)))\n",
    "\n",
    "        # If hitting a wall, stay in place\n",
    "        if gw.state_types[next_state] == 2:\n",
    "            next_state = state\n",
    "\n",
    "        # Get reward and update state\n",
    "        reward = gw.rewards[next_state] + gw.step_reward\n",
    "        total_reward += reward\n",
    "        trajectory.append((state, action, reward))  # Store trajectory\n",
    "\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "\n",
    "        # Check if we reached a terminal state\n",
    "        if gw.state_types[state] == 1:\n",
    "            done = True\n",
    "\n",
    "    return trajectory, total_reward, steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon-Greedy Policy for Gridworld\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `EpsilonGreedyPolicy` class implements an **epsilon-greedy policy** for a **Gridworld** environment. This policy is commonly used in **reinforcement learning** to balance **exploration** (trying new actions) and **exploitation** (choosing the best-known action).\n",
    "\n",
    "### How It Works\n",
    "\n",
    "- With probability **(1 - epsilon)**, the agent selects the action with the highest estimated value (greedy choice).\n",
    "- With probability **epsilon**, the agent selects a random action to encourage exploration.\n",
    "- The policy maintains a **state-action value table**, which is updated as the agent learns.\n",
    "\n",
    "---\n",
    "\n",
    "## Usage Guide\n",
    "\n",
    "### 1. **Initializing the Policy**\n",
    "To create an epsilon-greedy policy, define the shape of the Gridworld and the exploration parameter (`epsilon`):\n",
    "\n",
    "```python\n",
    "from epsilon_greedy_policy import EpsilonGreedyPolicy\n",
    "\n",
    "# Define grid size (e.g., 3x4 gridworld)\n",
    "grid_shape = (3, 4)\n",
    "\n",
    "# Initialize policy with 4 possible actions (Up, Right, Down, Left) and epsilon=0.1\n",
    "policy = EpsilonGreedyPolicy(shape=grid_shape, num_actions=4, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EpsilonGreedyPolicy:\n",
    "    \"\"\"\n",
    "    An epsilon-greedy policy for the Gridworld environment.\n",
    "\n",
    "    This policy selects the action with the highest estimated value most of the time \n",
    "    (1 - epsilon probability), while occasionally choosing a random action (epsilon probability) \n",
    "    to encourage exploration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape, num_actions=4, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the epsilon-greedy policy.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        shape : tuple\n",
    "            The shape of the environment grid (rows, cols).\n",
    "        num_actions : int, optional\n",
    "            The number of possible actions (default is 4: Up, Right, Down, Left).\n",
    "        epsilon : float, optional\n",
    "            The probability of selecting a random action instead of the greedy action (default is 0.1).\n",
    "        \"\"\"\n",
    "        self.shape = shape\n",
    "        self.num_actions = num_actions\n",
    "        self.epsilon = epsilon\n",
    "        self.policy = {(x, y): [0.0 for _ in range(num_actions)] for x in range(shape[0]) for y in range(shape[1])}\n",
    "\n",
    "    def argmax(self, actions):\n",
    "        \"\"\"\n",
    "        Returns the index of the action with the highest estimated value.\n",
    "\n",
    "        If multiple actions have the same highest value, one is selected randomly.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        actions : list\n",
    "            A list of action values.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        int\n",
    "            The index of the action with the highest estimated value.\n",
    "        \"\"\"\n",
    "        max_a = max(actions)\n",
    "        return np.random.choice([i for i, a in enumerate(actions) if a == max_a])\n",
    "\n",
    "    def __call__(self, state):\n",
    "        \"\"\"\n",
    "        Selects an action for the given state using the epsilon-greedy strategy.\n",
    "\n",
    "        With probability `epsilon`, a random action is chosen (exploration).\n",
    "        Otherwise, the action with the highest known value is selected (exploitation).\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        state : tuple\n",
    "            The (row, col) position in the grid.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        int\n",
    "            The selected action (0=Up, 1=Right, 2=Down, 3=Left).\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, self.num_actions)  # Explore: choose a random action\n",
    "        else:\n",
    "            return self.argmax(self.policy[state])\n",
    "\n",
    "    def update_policy(self, state, action, value):\n",
    "        \"\"\"\n",
    "        Updates the estimated value of a specific action in a given state.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        state : tuple\n",
    "            The (row, col) position in the grid.\n",
    "        action : int\n",
    "            The action index (0=Up, 1=Right, 2=Down, 3=Left).\n",
    "        value : float\n",
    "            The new estimated value for the given state-action pair.\n",
    "        \"\"\"\n",
    "        self.policy[state][action] = value\n",
    "\n",
    "    def get_state_action_value(self, state, action):\n",
    "        \"\"\"\n",
    "        Retrieves the estimated value of a specific state-action pair.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        state : tuple\n",
    "            The (row, col) position in the grid.\n",
    "        action : int\n",
    "            The action index.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float\n",
    "            The estimated value of taking the given action in the given state.\n",
    "        \"\"\"\n",
    "        return self.policy[state][action]\n",
    "\n",
    "\n",
    "    def get_greedy_policy(self):\n",
    "        \"\"\"\n",
    "        Extracts the greedy policy from the current estimated values.\n",
    "\n",
    "        The greedy policy selects the action with the highest estimated value in each state.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        np.ndarray\n",
    "            A 2D array where each element represents the best action for that state.\n",
    "        \"\"\"\n",
    "        greedy_policy = np.zeros(self.shape, dtype=int)\n",
    "        for state in self.policy:\n",
    "            greedy_policy[state] = self.argmax(self.policy[state])\n",
    "        return greedy_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -1, Steps taken: 22\n",
      "Trajectory:\n",
      "State: (2, 0), Action: 1, Reward: 0\n",
      "State: (2, 1), Action: 3, Reward: 0\n",
      "State: (2, 0), Action: 0, Reward: 0\n",
      "State: (1, 0), Action: 2, Reward: 0\n",
      "State: (2, 0), Action: 2, Reward: 0\n",
      "State: (2, 0), Action: 2, Reward: 0\n",
      "State: (2, 0), Action: 1, Reward: 0\n",
      "State: (2, 1), Action: 3, Reward: 0\n",
      "State: (2, 0), Action: 1, Reward: 0\n",
      "State: (2, 1), Action: 0, Reward: 0\n",
      "State: (2, 1), Action: 1, Reward: 0\n",
      "State: (2, 2), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 2, Reward: 0\n",
      "State: (2, 3), Action: 2, Reward: 0\n",
      "State: (2, 3), Action: 1, Reward: 0\n",
      "State: (2, 3), Action: 2, Reward: 0\n",
      "State: (2, 3), Action: 2, Reward: 0\n",
      "State: (2, 3), Action: 0, Reward: -1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "policy = EpsilonGreedyPolicy(shape, epsilon=0.1)\n",
    "trajectory, total_reward, steps = simulate(gw, policy,max_steps=1000)\n",
    "\n",
    "print(f\"Total reward: {total_reward}, Steps taken: {steps}\")\n",
    "print(\"Trajectory:\")\n",
    "for t in trajectory:\n",
    "    print(f\"State: {t[0]}, Action: {t[1]}, Reward: {t[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MC](assets/OPMCFV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def monte_carlo_first_visit(gw, policy, num_episodes=1000, gamma=0.9):\n",
    "    \"\"\"\n",
    "    Monte Carlo First-Visit Control using an epsilon-greedy policy.\n",
    "    \n",
    "    Parameters:\n",
    "    gw (Gridworld): The Gridworld object.\n",
    "    policy (EpsilonGreedyPolicy): The epsilon-greedy policy object.\n",
    "    num_episodes (int): Number of episodes to run.\n",
    "    gamma (float): Discount factor for future rewards.\n",
    "    \n",
    "    Returns:\n",
    "    Q (dict): State-action value function.\n",
    "    policy (EpsilonGreedyPolicy): Updated policy after learning.\n",
    "    \"\"\"\n",
    "    # Initialize Q-value function and returns tracking\n",
    "    Q = defaultdict(lambda: [0.0] * policy.num_actions)\n",
    "    returns = defaultdict(list)  # Stores returns for each (state, action) pair\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        trajectory, total_reward, steps = simulate(gw, policy)  # Generate an episode\n",
    "        \n",
    "        G = 0  # Initialize return\n",
    "        visited = set()  # Track first visits\n",
    "        \n",
    "        # Reverse iterate through the episode to calculate returns\n",
    "        for t in reversed(range(len(trajectory))):\n",
    "            state, action, reward = trajectory[t]\n",
    "            G = gamma * G + reward  # Discounted return\n",
    "            \n",
    "            if (state, action) not in visited:  # First-visit check\n",
    "                visited.add((state, action))\n",
    "                returns[(state, action)].append(G)\n",
    "                \n",
    "                # Update Q-value function\n",
    "                Q[state][action] = np.mean(returns[(state, action)])  # Average returns\n",
    "                \n",
    "                # Policy improvement: Choose best action with epsilon-greedy\n",
    "                policy.update_policy(state, np.argmax(Q[state]), np.max(Q[state]))\n",
    "    \n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode}/{num_episodes} complete.\")\n",
    "\n",
    "    return Q, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/10000 complete.\n",
      "Episode 100/10000 complete.\n",
      "Episode 200/10000 complete.\n",
      "Episode 300/10000 complete.\n",
      "Episode 400/10000 complete.\n",
      "Episode 500/10000 complete.\n",
      "Episode 600/10000 complete.\n",
      "Episode 700/10000 complete.\n",
      "Episode 800/10000 complete.\n",
      "Episode 900/10000 complete.\n",
      "Episode 1000/10000 complete.\n",
      "Episode 1100/10000 complete.\n",
      "Episode 1200/10000 complete.\n",
      "Episode 1300/10000 complete.\n",
      "Episode 1400/10000 complete.\n",
      "Episode 1500/10000 complete.\n",
      "Episode 1600/10000 complete.\n",
      "Episode 1700/10000 complete.\n",
      "Episode 1800/10000 complete.\n",
      "Episode 1900/10000 complete.\n",
      "Episode 2000/10000 complete.\n",
      "Episode 2100/10000 complete.\n",
      "Episode 2200/10000 complete.\n",
      "Episode 2300/10000 complete.\n",
      "Episode 2400/10000 complete.\n",
      "Episode 2500/10000 complete.\n",
      "Episode 2600/10000 complete.\n",
      "Episode 2700/10000 complete.\n",
      "Episode 2800/10000 complete.\n",
      "Episode 2900/10000 complete.\n",
      "Episode 3000/10000 complete.\n",
      "Episode 3100/10000 complete.\n",
      "Episode 3200/10000 complete.\n",
      "Episode 3300/10000 complete.\n",
      "Episode 3400/10000 complete.\n",
      "Episode 3500/10000 complete.\n",
      "Episode 3600/10000 complete.\n",
      "Episode 3700/10000 complete.\n",
      "Episode 3800/10000 complete.\n",
      "Episode 3900/10000 complete.\n",
      "Episode 4000/10000 complete.\n",
      "Episode 4100/10000 complete.\n",
      "Episode 4200/10000 complete.\n",
      "Episode 4300/10000 complete.\n",
      "Episode 4400/10000 complete.\n",
      "Episode 4500/10000 complete.\n",
      "Episode 4600/10000 complete.\n",
      "Episode 4700/10000 complete.\n",
      "Episode 4800/10000 complete.\n",
      "Episode 4900/10000 complete.\n",
      "Episode 5000/10000 complete.\n",
      "Episode 5100/10000 complete.\n",
      "Episode 5200/10000 complete.\n",
      "Episode 5300/10000 complete.\n",
      "Episode 5400/10000 complete.\n",
      "Episode 5500/10000 complete.\n",
      "Episode 5600/10000 complete.\n",
      "Episode 5700/10000 complete.\n",
      "Episode 5800/10000 complete.\n",
      "Episode 5900/10000 complete.\n",
      "Episode 6000/10000 complete.\n",
      "Episode 6100/10000 complete.\n",
      "Episode 6200/10000 complete.\n",
      "Episode 6300/10000 complete.\n",
      "Episode 6400/10000 complete.\n",
      "Episode 6500/10000 complete.\n",
      "Episode 6600/10000 complete.\n",
      "Episode 6700/10000 complete.\n",
      "Episode 6800/10000 complete.\n",
      "Episode 6900/10000 complete.\n",
      "Episode 7000/10000 complete.\n",
      "Episode 7100/10000 complete.\n",
      "Episode 7200/10000 complete.\n",
      "Episode 7300/10000 complete.\n",
      "Episode 7400/10000 complete.\n",
      "Episode 7500/10000 complete.\n",
      "Episode 7600/10000 complete.\n",
      "Episode 7700/10000 complete.\n",
      "Episode 7800/10000 complete.\n",
      "Episode 7900/10000 complete.\n",
      "Episode 8000/10000 complete.\n",
      "Episode 8100/10000 complete.\n",
      "Episode 8200/10000 complete.\n",
      "Episode 8300/10000 complete.\n",
      "Episode 8400/10000 complete.\n",
      "Episode 8500/10000 complete.\n",
      "Episode 8600/10000 complete.\n",
      "Episode 8700/10000 complete.\n",
      "Episode 8800/10000 complete.\n",
      "Episode 8900/10000 complete.\n",
      "Episode 9000/10000 complete.\n",
      "Episode 9100/10000 complete.\n",
      "Episode 9200/10000 complete.\n",
      "Episode 9300/10000 complete.\n",
      "Episode 9400/10000 complete.\n",
      "Episode 9500/10000 complete.\n",
      "Episode 9600/10000 complete.\n",
      "Episode 9700/10000 complete.\n",
      "Episode 9800/10000 complete.\n",
      "Episode 9900/10000 complete.\n"
     ]
    }
   ],
   "source": [
    "policy = EpsilonGreedyPolicy(shape, epsilon=0.1)\n",
    "Q, updated_policy = monte_carlo_first_visit(gw, policy, num_episodes=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_p = policy.get_greedy_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def q_dict_to_array(q_dict, shape):\n",
    "    \"\"\"\n",
    "    Converts a Q-value dictionary into a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    q_dict (dict): Dictionary mapping (state) -> [Q-values for actions].\n",
    "    shape (tuple): Shape of the environment grid (height, width).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: NumPy array of shape (height, width, num_actions).\n",
    "    \"\"\"\n",
    "    height, width = shape\n",
    "    num_actions = 4  # Assuming 4 actions (Up, Right, Down, Left)\n",
    "\n",
    "    # Initialize Q-table with zeros\n",
    "    q_array = np.zeros((height, width, num_actions))\n",
    "\n",
    "    # Populate array with dictionary values\n",
    "    for (i, j), q_values in q_dict.items():\n",
    "        q_array[i, j, :] = q_values  # Assign Q-values to the respective state\n",
    "\n",
    "    return q_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = q_dict_to_array(policy.policy, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_p = policy.get_greedy_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=601x451>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw.render(q_table,policy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
