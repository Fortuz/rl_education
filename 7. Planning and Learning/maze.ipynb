{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6b7a47-954c-47e7-b711-799901326092",
   "metadata": {},
   "source": [
    "![Logo](../assets/logo.png)\n",
    "\n",
    "Made by **Domonkos Nagy**\n",
    "\n",
    "[<img src=\"../assets/open_button.png\">](https://colab.research.google.com/github/Fortuz/rl_education/blob/main/7.%20Planning%20and%20Learning/maze.ipynb)\n",
    "\n",
    "# Maze\n",
    "\n",
    "In this notebook we consider the problem of solving a maze in only a few episodes.\n",
    "\n",
    "![Example](assets/maze.gif)\n",
    "\n",
    "This maze environment was originally made with the `gym` library, but we apply an API compatibility layer, so it behaves exactly like\n",
    "a `gymnasium` environment. The states are the x, y coordinates of the agent (which we transform to be respresented by a single integer), and the actions are the 4 directions: 'N', 'S', 'E' and 'W'. The reward\n",
    "is -0.1/(number of cells) for each step, and for reaching the goal, a reward of +1 is received.\n",
    "\n",
    "The maze is randomly generated every time the environment is created. To find the optimal path in only a small number of episodes, we are going to use\n",
    "*Prioritized Sweeping*.\n",
    "\n",
    "- Documentation for the Maze environment: https://github.com/MattChanTK/gym-maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217b9e4d-1854-405c-9266-803b34915fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_maze\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from gymnasium.wrappers import TransformObservation\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabb6faf-27bb-44e4-98c4-e136f0e4dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: XDG_RUNTIME_DIR not set in the environment.\n"
     ]
    }
   ],
   "source": [
    "# initializing gym environment with gymnasium compatibility\n",
    "env = gym.make(\"maze-random-10x10-v0\", apply_api_compatibility=True)\n",
    "# transforming observation representation from array to int: e.g. [3, 4] -> 43\n",
    "env = TransformObservation(env, lambda obs: int(obs[1] * (env.observation_space.high + 1)[0] + obs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f93420e-b1af-4142-b48c-15bb04474f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing q-table\n",
    "action_space_size = env.action_space.n\n",
    "observation_space_size = (env.observation_space.high + 1)[0] * \\\n",
    "    (env.observation_space.high + 1)[1]\n",
    "shape = observation_space_size, action_space_size\n",
    "\n",
    "q_table = np.zeros(shape)\n",
    "\n",
    "# initializing model\n",
    "model_state = np.zeros(shape)\n",
    "model_reward = np.zeros(shape)\n",
    "\n",
    "# initializing priority queue\n",
    "priorities = np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36954da-d9e2-4a34-832f-f7133beee555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax function that breaks ties randomly\n",
    "def argmax(arr):\n",
    "    arr_max = np.max(arr)\n",
    "    return np.random.choice(np.where(arr == arr_max)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c13ee-8ee9-4e3f-8de8-2f5a6b66ae22",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "In addition to the Q-table, the agent also learns a model of the environment. Since the maze is deterministic, the model is pretty simple:\n",
    "for each state-action pair, the model stores the next state and reward: $\\text{Model}(S_t, A_t) = R_{t+1}, S_{t+1}$. The `add` method\n",
    "is used to add new information to the model, while the `get` method returns the reward and next state for a given state-action pair.\n",
    "The `get_leading` method returns all state-action pairs that lead to a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a59e5c6-abd4-44a6-8363-020a9bb84e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class representing our model of the environment\n",
    "class Model:\n",
    "    def __init__(self, shape):\n",
    "        self.states = np.zeros(shape, dtype=int) - 1\n",
    "        self.rewards = np.zeros(shape)\n",
    "        self.states_reverse = {}\n",
    "\n",
    "    # add new information to the model:\n",
    "    # taking 'action' in 'state' produces 'reward'\n",
    "    # and transfers the agent to 'new_state'\n",
    "    def add(self, state, action, reward, new_state):\n",
    "        self.states[state, action] = new_state\n",
    "        self.rewards[state, action] = reward\n",
    "\n",
    "        if new_state in self.states_reverse:\n",
    "            if not (state, action) in self.states_reverse[new_state]:\n",
    "                self.states_reverse[new_state].append((state, action))\n",
    "        else:\n",
    "            self.states_reverse[new_state] = [(state, action)]\n",
    "\n",
    "    # get information from the model:\n",
    "    def get(self, state, action):\n",
    "        new_state = self.states[state, action]\n",
    "        reward = self.rewards[state, action]\n",
    "        return new_state, reward\n",
    "\n",
    "    # get all state-action pairs that lead the agent to 'state'\n",
    "    def get_leading(self, state):\n",
    "        return self.states_reverse[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884fe2c1-1599-4702-9516-ab9e21cc7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing model\n",
    "model = Model(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307c573-e7b8-40c0-b234-6e3b52cd1327",
   "metadata": {},
   "source": [
    "## Prioritized Sweeping\n",
    "\n",
    "Prioritized sweeping works similarly to Q-learning, but in addition to updates based on real experience (*learning*) it also utilizes updates based on simulated\n",
    "experience (*planning*). To be able to do this, the algorithm records each state transition, forming a model of the environment.\n",
    "\n",
    "A simpler, similar algorithm is called *Dyna-Q*: it is essentially Q-learning with state transitions being recorded to a model, and after each step, randomly selected\n",
    "Q-values are being updated using information from the model.\n",
    "Prioritized sweeping improves on Dyna-Q by focusing on updating state-action pairs with higher temporal-difference error values more frequently. By prioritizing updates based on the magnitude of the error, it accelerates the learning process by directing attention to the most critical areas of the environment, where value estimates need refinement, leading to quicker convergence.\n",
    "\n",
    "Since state-action pairs that lead to a state with a high error are likely to have a high TD error themselves, after each update, the errors of state-action pairs that lead to the newly updated state are recalculated. This leads to a quick backpropagation of rewards: for example, in the maze environment, after the goal state is reached, prioritized sweeping will\n",
    "first update the state-action pair leading to the goal state, then the state-action pairs leading to the state just before the goal state, and so on, spreading backwards from the\n",
    "goal to the starting state.\n",
    "\n",
    "In this example, the agent learns to solve the maze in only 3 episodes, with 200 planning updates after each step. In real-world applications, learning and planning are usually parallelized: the agent is always reactive and always deliberative, responding instantly to the latest sensory information and yet always planning in the\n",
    "background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b306b4-6004-406c-90e7-0daa1f17ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "N_EPISODES = 3\n",
    "N_UPDATES_PER_STEP = 200  # planning updates per interaction with the environment\n",
    "\n",
    "ALPHA = 0.7  # learning rate\n",
    "GAMMA = 1  # discount rate\n",
    "THETA = 0.01  # priority treshold\n",
    "C = 5  # exploration rate (UCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ca6b72-6124-4a22-bda1-071e88fadd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan():\n",
    "    for _ in range(N_UPDATES_PER_STEP):\n",
    "        # get state-action pair with highest priority\n",
    "        state, action = np.unravel_index(priorities.argmax(), priorities.shape)\n",
    "        if priorities[state, action] == 0:\n",
    "            break\n",
    "\n",
    "        # reset priority\n",
    "        priorities[state, action] = 0\n",
    "\n",
    "        # get new state and reward from model\n",
    "        new_state, reward = model.get(state, action)\n",
    "\n",
    "        # update q-table\n",
    "        q_table[state, action] = q_table[state, action] * (1 - ALPHA) + \\\n",
    "            ALPHA * (reward + GAMMA * np.max(q_table[new_state, :]))\n",
    "\n",
    "        # add leading states to queue\n",
    "        for prev_state, prev_action in model.get_leading(state):\n",
    "            _, prev_reward = model.get(prev_state, prev_action)\n",
    "            priority = abs(prev_reward + GAMMA *\n",
    "                           np.max(q_table[state, :] - q_table[prev_state, prev_action]))\n",
    "\n",
    "            if priorities[prev_state, prev_action] < priority and priority > THETA:\n",
    "                priorities[prev_state, prev_action] = priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfcb921-5953-4911-af60-5042349d20ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0:\n",
      "\tSteps: 3205\n",
      "\tQueue size: 65\n",
      "Episode 1:\n",
      "\tSteps: 39\n",
      "\tQueue size: 100\n",
      "Episode 2:\n",
      "\tSteps: 36\n",
      "\tQueue size: 45\n"
     ]
    }
   ],
   "source": [
    "for episode in range(N_EPISODES):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    n = 0\n",
    "    selections = np.zeros(shape)\n",
    "\n",
    "    while not done:\n",
    "        n += 1\n",
    "\n",
    "        # UCB action selection\n",
    "        UCB_estimations = q_table[state, :] + C * np.sqrt(np.log(n) / (selections[state, :] + 1e-5))\n",
    "        action = argmax(UCB_estimations)\n",
    "\n",
    "        selections[state, action] += 1\n",
    "\n",
    "        # take the selected action\n",
    "        new_state, reward, done, truncated, info = env.step(['N', 'S', 'E', 'W'][action])\n",
    "        # add information to the model\n",
    "        model.add(state, action, reward, new_state)\n",
    "\n",
    "        # add state-action pair to queue\n",
    "        priority = abs(reward + GAMMA *\n",
    "                       np.max(q_table[new_state, :] - q_table[state, action]))\n",
    "\n",
    "        if priorities[state, action] < priority and priority > THETA:\n",
    "            priorities[state, action] = priority\n",
    "\n",
    "        state = new_state\n",
    "        plan()\n",
    "\n",
    "    print(f'Episode {episode}:\\n\\tSteps: {n}\\n\\tQueue size: {np.count_nonzero(priorities)}')\n",
    "    \n",
    "# Save the q-table\n",
    "with open('q_table.bin', 'wb') as f:\n",
    "    pickle.dump(q_table, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ef255-664b-4a29-8892-247961db4a99",
   "metadata": {},
   "source": [
    "**Playing the game**: Here we simulate an episode using the resulting policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18f6bea-6cf1-4ec7-a68e-3589b2508b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initializing gym environment with gymnasium compatibility\n",
    "env = gym.make(\"maze-random-10x10-v0\", apply_api_compatibility=True)\n",
    "# transforming observation representation from array to int: e.g. [3, 4] -> 43\n",
    "env = TransformObservation(env, lambda obs: int(obs[1] * (env.observation_space.high + 1)[0] + obs[0]))\n",
    "\n",
    "# Load the q-table\n",
    "with open('q_table.bin', 'rb') as f:\n",
    "    q_table = pickle.load(f)\n",
    "    \n",
    "# create figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.tick_params(left=False, right=False, labelleft=False,\n",
    "                labelbottom=False, bottom=False)\n",
    "\n",
    "# render starting state\n",
    "state, _ = env.reset()\n",
    "img = plt.imshow(env.render())\n",
    "\n",
    "done = False\n",
    "n_steps = 0\n",
    "\n",
    "# play episode\n",
    "while not done:\n",
    "    # greedy action selection\n",
    "    action = argmax(q_table[state, :])\n",
    "\n",
    "    # take the selected action\n",
    "    new_state, reward, done, truncated, info = env.step(['N', 'S', 'E', 'W'][action])\n",
    "    n_steps += 1\n",
    "\n",
    "    # render state\n",
    "    img.set_data(env.render())\n",
    "    plt.title(f'Steps taken: {n_steps}')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a9380-6342-46e1-9f8c-9c68487752d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
